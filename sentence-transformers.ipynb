{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f506b3a9-ea3d-485f-b6ce-a397fa1733e0",
   "metadata": {},
   "source": [
    "# Sentence Transformers 학습과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90a5cb-440e-42b4-850d-11b651870aa5",
   "metadata": {},
   "source": [
    "본 노트북에서는 `klue/roberta-base` 모델을 **KLUE** 내 **STS** 데이터셋을 활용하여 훈련하는 예제를 다루게 됩니다.\n",
    "\n",
    "학습을 통해 얻어진 `sentence-klue-roberta-base` 모델은 입력된 문장의 임베딩을 계산해 유사도를 예측하는데 사용할 수 있게 됩니다.\n",
    "\n",
    "학습 과정 이후에는 간단한 예제 코드를 통해 모델이 어떻게 활용되는지도 함께 알아보도록 할 것입니다.\n",
    "\n",
    "모든 소스 코드는 [`sentence-transformers`](https://github.com/UKPLab/sentence-transformers) 원 라이브러리를 참고하였습니다.\n",
    "\n",
    "먼저, 노트북을 실행하는데 필요한 라이브러리를 설치합니다. 모델 훈련을 위해서는 `sentence-transformers`가, 학습 데이터셋 로드를 위해서는 `datasets` 라이브러리의 설치가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad90326-2557-4b86-a42a-ca5033a09cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e01af-199f-4fdf-b934-4211d8bf4592",
   "metadata": {},
   "source": [
    "## Sentence Transformers 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431cd47-5f9b-44a0-a1a9-8aa500eb89ff",
   "metadata": {},
   "source": [
    "노트북을 실행하는데 필요한 라이브러리들을 모두 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21b5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb62c66-83b4-43c3-a709-18080a816105",
   "metadata": {},
   "source": [
    "학습 경과를 지켜보는데 사용할 *logger* 를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238f04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb0c2f",
   "metadata": {},
   "source": [
    "학습에 필요한 정보를 변수로 기록해둡니다.\n",
    "\n",
    "본 노트북에서는 `klue-roberta-base` 모델을 활용하지만, https://huggingface.co/klue 페이지에서 더 다양한 사전학습 언어 모델을 확인하실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536bc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"klue/roberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35e70f-1322-4dc2-b903-25248555e779",
   "metadata": {},
   "source": [
    "모델 정보 외에도 학습에 필요한 하이퍼 파라미터를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7484dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/training_klue_sts_' + model_name.replace(\"/\", \"-\") + '-' + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d438e-5f39-419a-a25b-4c78a0a4d2a7",
   "metadata": {},
   "source": [
    "앞서 정의한 사전학습 언어 모델을 로드합니다.\n",
    "\n",
    "`sentence-transformers`는 HuggingFace의 `transformers`와 호환이 잘 이루어지고 있기 때문에, [모델 허브](https://huggingface.co/models)에 올라와있는 대부분의 언어 모델을 임베딩을 추출할 *Embedder* 로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd44fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = models.Transformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e09dc6-5115-499e-a409-8b9b3876ce30",
   "metadata": {},
   "source": [
    "*Embedder* 에서 추출된 토큰 단위 임베딩들을 가지고 문장 임베딩을 어떻게 계산할 것인지를 결정하는 *Pooler* 를 정의합니다.\n",
    "\n",
    "여러 Pooling 기법이 있겠지만, 예제 노트북에서는 **Mean Pooling**을 사용하기로 합니다.\n",
    "\n",
    "**Mean Pooling**이란 모델이 반환한 모든 토큰 임베딩을 더해준 후, 더해진 토큰 개수만큼 나누어 문장을 대표하는 임베딩으로 사용하는 기법을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361b75b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:24:22 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "pooler = models.Pooling(\n",
    "    embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e61463-27d9-4538-ad54-74aa08383857",
   "metadata": {},
   "source": [
    "*Embedder* 와 *Pooler* 를 정의했으므로, 이 두 모듈로 구성된 하나의 모델을 정의합니다.\n",
    "\n",
    "`modules`에 입력으로 들어가는 모듈이 순차적으로 임베딩 과정에 사용이 된다고 생각하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a967d3-6118-4b02-a5b6-1815c8125510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(modules=[embedding_model, pooler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06323b50-d9ac-4c37-8d16-d81ea1104a11",
   "metadata": {},
   "source": [
    "이제 학습에 사용될 KLUE STS 데이터셋을 다운로드 및 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635169fc-d2aa-4113-99f8-a64ab5bde282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:24:24 - Reusing dataset klue (/root/.cache/huggingface/datasets/klue/sts/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"klue\", \"sts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c899baa-e1c5-43f1-9324-9222b7ea495f",
   "metadata": {},
   "source": [
    "다운로드 혹은 로드 후 얻어진 `datasets` 객체를 살펴보면, 훈련 데이터와 검증 데이터가 포함되어 이쓴ㄴ 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ec808e-acb8-4770-ad3e-7e8aa5de2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['guid', 'labels', 'sentence1', 'sentence2', 'source'],\n",
       "        num_rows: 11668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['guid', 'labels', 'sentence1', 'sentence2', 'source'],\n",
       "        num_rows: 519\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb3c8a-e64f-490e-a864-534018c05fea",
   "metadata": {},
   "source": [
    "각 예시 데이터는 아래와 같이 두 개의 문장과 두 문장의 유사도를 라벨로 지니고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81ed4e3-8ccc-4362-96ea-8ac5e8d42523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'klue-sts-v1_train_00000',\n",
       " 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1},\n",
       " 'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
       " 'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.',\n",
       " 'source': 'airbnb-rtt'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6780db-0594-4bfe-a9fd-46e03e171092",
   "metadata": {},
   "source": [
    "이제 테스트에 활용할 데이터를 얻어야 할 차례입니다.\n",
    "\n",
    "위에서 살펴본 바와 같이 KLUE 내 STS 데이터셋은 테스트 데이터셋을 포함하고 있지 않습니다.\n",
    "\n",
    "따라서 실습의 원활한 진행을 위해 다른 벤치마크 STS 데이터셋인 KorSTS 데이터셋을 다운로드 및 로드하여 사용하도록 하겠습니다.\n",
    "\n",
    "(\\* 두 데이터셋은 제작 과정이 엄밀히 다르므로, KLUE STS 데이터에 대해 학습된 모델이 KorSTS 테스트셋에 대해 기록하는 점수은 사실상 큰 의미가 없을 수 있습니다. 전체적인 훈련 프로세스의 이해를 돕기 위해 사용한다고 생각해주시는게 좋습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09d37e9-9424-4bfb-abef-67d40cda624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:24:25 - Reusing dataset kor_nlu (/root/.cache/huggingface/datasets/kor_nlu/sts/1.0.0/4facbba77df60b0658056ced2052633e681a50187b9428bd5752ebd59d332ba8)\n"
     ]
    }
   ],
   "source": [
    "testsets = load_dataset(\"kor_nlu\", \"sts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155ae3e-ef28-46d2-a4c0-0624c05b2ea2",
   "metadata": {},
   "source": [
    "KorSTS 데이터셋은 훈련, 검증 그리고 테스트셋을 지니고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92474875-b1bb-46fb-9865-7a4b27de753b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['filename', 'genre', 'id', 'score', 'sentence1', 'sentence2', 'year'],\n",
       "        num_rows: 5703\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['filename', 'genre', 'id', 'score', 'sentence1', 'sentence2', 'year'],\n",
       "        num_rows: 1471\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['filename', 'genre', 'id', 'score', 'sentence1', 'sentence2', 'year'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72659878-2651-4286-b049-3e1d1cfafe34",
   "metadata": {},
   "source": [
    "KorSTS의 예시 데이터도 마찬가지로 두 문장과 두 문장 간 유사도를 지니고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db255fd-627d-46a8-a2e1-cf8b7a4cad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 2,\n",
       " 'genre': 1,\n",
       " 'id': 24,\n",
       " 'score': 2.5,\n",
       " 'sentence1': '한 소녀가 머리를 스타일링하고 있다.',\n",
       " 'sentence2': '한 소녀가 머리를 빗고 있다.',\n",
       " 'year': 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsets[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadcf99a-dcdc-4496-8380-978cfe5f3322",
   "metadata": {},
   "source": [
    "이제 앞서 얻어진 데이터셋을 `sentence-transformers` 훈련 양식에 맞게 변환해주는 작업을 거쳐야 합니다.\n",
    "\n",
    "두 데이터 모두 0점에서 5점 사이의 값으로 유사도가 기록되었기 때문에, 0.0 ~ 1.0 스케일로 정규화를 시켜주는 작업을 거치게 됩니다.\n",
    "\n",
    "(\\* KorSTS 내 테스트셋의 경우 `None`으로 기록된 문장이 몇 개 존재하여, `None`을 걸러주는 조건이 추가되었습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "647c049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:57:05 - Read STSbenchmark train dataset\n"
     ]
    }
   ],
   "source": [
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "# KLUE STS 내 훈련, 검증 데이터 예제 변환\n",
    "for phase in [\"train\", \"validation\"]:\n",
    "    examples = datasets[phase]\n",
    "\n",
    "    for example in examples:\n",
    "        score = float(example['labels']['label']) / 5.0  # 0.0 ~ 1.0 스케일로 유사도 정규화\n",
    "\n",
    "        inp_example = InputExample(\n",
    "            texts=[example['sentence1'], example['sentence2']], \n",
    "            label=score,\n",
    "        )\n",
    "\n",
    "        if phase == 'validation':\n",
    "            dev_samples.append(inp_example)\n",
    "        else:\n",
    "            train_samples.append(inp_example)\n",
    "\n",
    "# KorSTS 내 테스트 데이터 예제 변환\n",
    "for example in testsets[\"test\"]:\n",
    "    score = float(example['score']) / 5.0\n",
    "\n",
    "    if example['sentence1'] and example['sentence2']:\n",
    "        inp_example = InputExample(\n",
    "            texts=[example['sentence1'], example['sentence2']],\n",
    "            label=score,\n",
    "        )\n",
    "\n",
    "    test_samples.append(inp_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905167a-b301-495d-97fa-0c33e773939c",
   "metadata": {},
   "source": [
    "앞선 로직을 통해 각 데이터 예제는 다음과 같이 `InputExample` 객체로 변환되게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de3d5b8-6572-4d6e-bb5b-88efc9daf1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
       "  '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.'],\n",
       " 0.74)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0].texts, train_samples[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afb8c68a-fa6e-4730-af55-824868661135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['한 소녀가 머리를 스타일링하고 있다.', '한 소녀가 머리를 빗고 있다.'], 0.5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples[0].texts, test_samples[0].label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd7bb4-a621-4814-b770-e5ecc8004fab",
   "metadata": {},
   "source": [
    "이제 학습에 사용될 `DataLoader`와 **Loss**를 설정해주도록 합니다.\n",
    "\n",
    "`CosineSimilarityLoss`는 입력된 두 문장의 임베딩 간 코사인 유사도와 골드 라벨 간 차이를 통해 계산되게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c30838cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_samples,\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    ")\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc603d4-77ad-4cb4-9276-161e42f11f4d",
   "metadata": {},
   "source": [
    "모델 검증에 활용할 **Evaluator** 를 정의해줍니다.\n",
    "\n",
    "앞서 얻어진 검증 데이터를 활용하여, 모델의 문장 임베딩 간 코사인 유사도가 얼마나 골드 라벨에 가까운지 계산하는 역할을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dee8198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:24:27 - Read STSbenchmark dev dataset\n"
     ]
    }
   ],
   "source": [
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    dev_samples,\n",
    "    name=\"sts-dev\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4a9891b2-70de-41e5-92c2-3541ab9192b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader) * num_epochs * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d09d6-f086-4ccb-a213-46f95a9b1d37",
   "metadata": {},
   "source": [
    "모델 학습에 사용될 **Warm up Steps**를 설정합니다.\n",
    "\n",
    "다양한 방법으로 스텝 수를 결정할 수 있겠지만, 예제 노트북에서는 원 예제 코드를 따라 훈련 배치 수의 10% 만큼으로 값을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fdbcaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-18 23:24:27 - Warmup-steps: 146\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs  * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e262b",
   "metadata": {},
   "source": [
    "이제 앞서 얻어진 객체, 값들을 가지고 모델의 훈련을 진행합니다.\n",
    "\n",
    "`sentence-transformers`에서는 다음과 같이 `fit` 함수를 통해 간단히 모델의 훈련과 검증이 가능합니다.\n",
    "\n",
    "훈련 과정을 통해 매 에폭 마다 얻어지는 체크포인트에 대해 *Evaluator* 가 학습된 모델의 코사인 유사도와 골드 라벨 간 피어슨, 스피어만 상관 계수를 계산해 기록을 남기게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360274d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fccf0569d044df87016378c0cac904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb3e52bbe0b4e9381b8005f8572fa83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=365.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-06-18 23:26:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2021-06-18 23:26:34 - Cosine-Similarity :\tPearson: 0.8695\tSpearman: 0.8657\n",
      "2021-06-18 23:26:34 - Manhattan-Distance:\tPearson: 0.8695\tSpearman: 0.8628\n",
      "2021-06-18 23:26:34 - Euclidean-Distance:\tPearson: 0.8699\tSpearman: 0.8634\n",
      "2021-06-18 23:26:34 - Dot-Product-Similarity:\tPearson: 0.8559\tSpearman: 0.8508\n",
      "2021-06-18 23:26:34 - Save model to output/training_stsbenchmark_klue-roberta-base-2021-06-18_23-24-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e3439851c14100b518a5679d6efecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=365.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-06-18 23:28:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 1:\n",
      "2021-06-18 23:28:37 - Cosine-Similarity :\tPearson: 0.8800\tSpearman: 0.8768\n",
      "2021-06-18 23:28:37 - Manhattan-Distance:\tPearson: 0.8793\tSpearman: 0.8733\n",
      "2021-06-18 23:28:37 - Euclidean-Distance:\tPearson: 0.8804\tSpearman: 0.8740\n",
      "2021-06-18 23:28:37 - Dot-Product-Similarity:\tPearson: 0.8721\tSpearman: 0.8665\n",
      "2021-06-18 23:28:37 - Save model to output/training_stsbenchmark_klue-roberta-base-2021-06-18_23-24-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7185dd5f8e4de4b2b831b80560e9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=365.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-06-18 23:30:39 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 2:\n",
      "2021-06-18 23:30:40 - Cosine-Similarity :\tPearson: 0.8865\tSpearman: 0.8857\n",
      "2021-06-18 23:30:40 - Manhattan-Distance:\tPearson: 0.8864\tSpearman: 0.8808\n",
      "2021-06-18 23:30:40 - Euclidean-Distance:\tPearson: 0.8874\tSpearman: 0.8819\n",
      "2021-06-18 23:30:40 - Dot-Product-Similarity:\tPearson: 0.8782\tSpearman: 0.8746\n",
      "2021-06-18 23:30:40 - Save model to output/training_stsbenchmark_klue-roberta-base-2021-06-18_23-24-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec71193d64a4f39a793a0cbb53fe790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=365.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-06-18 23:32:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 3:\n",
      "2021-06-18 23:32:44 - Cosine-Similarity :\tPearson: 0.8902\tSpearman: 0.8906\n",
      "2021-06-18 23:32:44 - Manhattan-Distance:\tPearson: 0.8893\tSpearman: 0.8849\n",
      "2021-06-18 23:32:44 - Euclidean-Distance:\tPearson: 0.8901\tSpearman: 0.8858\n",
      "2021-06-18 23:32:44 - Dot-Product-Similarity:\tPearson: 0.8820\tSpearman: 0.8792\n",
      "2021-06-18 23:32:44 - Save model to output/training_stsbenchmark_klue-roberta-base-2021-06-18_23-24-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16458123",
   "metadata": {},
   "source": [
    "학습이 완료되었다면 이제 학습된 모델을 테스트 할 시간입니다.\n",
    "\n",
    "앞서 KorSTS 데이터를 활용해 구축한 테스트 데이터셋을 앞서와 마찬가지로 *Evaluator* 로 초기화해주도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc63a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-19 01:06:04 - Load pretrained SentenceTransformer: output/training_stsbenchmark_klue-roberta-base-2021-06-18_23-24-12\n",
      "2021-06-19 01:06:04 - Load SentenceTransformer from folder: output/training_stsbenchmark_klue-roberta-base-2021-06-18_23-24-12\n",
      "2021-06-19 01:06:06 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99746cbe-3980-49ed-8880-58f71d04d8d0",
   "metadata": {},
   "source": [
    "이제 테스트 *Evaluator* 를 활용하여 테스트셋에 대해 각 상관 계수를 계산하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "57a412da-8106-4a9b-835f-9b9ff954a999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-19 00:51:22 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2021-06-19 00:51:25 - Cosine-Similarity :\tPearson: 0.7750\tSpearman: 0.7645\n",
      "2021-06-19 00:51:25 - Manhattan-Distance:\tPearson: 0.7691\tSpearman: 0.7670\n",
      "2021-06-19 00:51:25 - Euclidean-Distance:\tPearson: 0.7691\tSpearman: 0.7674\n",
      "2021-06-19 00:51:25 - Dot-Product-Similarity:\tPearson: 0.7425\tSpearman: 0.7311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7674370064710222"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9598bd1-bf9a-4abc-bf0a-d79f0b0f45a9",
   "metadata": {},
   "source": [
    "역시 검증 데이터에 비해 좋지 않은 점수를 기록하였습니다.\n",
    "\n",
    "KLUE 내 검증 데이터셋 중 일부를 샘플링하여 테스트셋으로 활용하는 방안도 있겠지만,\n",
    "\n",
    "본 노트북은 전체 훈련 프로세스를 파악하는데 초점을 맞추었으므로 실험을 마치도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d23d68-36ca-4709-b74a-b548887ad93a",
   "metadata": {},
   "source": [
    "## Sentence Transformers 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08565e0-549a-4344-b901-8a67cd60fd86",
   "metadata": {},
   "source": [
    "### 시맨틱 서치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8d2bd-29c8-4575-84d3-2c948ade5cd4",
   "metadata": {},
   "source": [
    "입력된 문장 간 유사도를 쉽고 빠르게 구할 수 있도록 설계된 `sentence-transformers`를 이용한다면 임베딩을 활용해 다양한 어플리케이션을 고안할 수 있습니다.\n",
    "\n",
    "먼저 여러 문장 후보군이 주어졌을 때, 입력된 문장과 가장 유사한 문장을 계산하는 예제를 살펴보도록 합시다.\n",
    "\n",
    "이를 위해 검색의 대상이 되는 문장 후보군을 다음과 같이 정의할 필요가 있습니다. 이후, 정의된 문장 후보군을 미리 임베딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c7639791-83ba-4a9b-bfd2-936d358c0c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69279c8f0d34bbcbe0d688b532f9600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    \"1992년 7월 8일 손흥민은 강원도 춘천시 후평동에서 아버지 손웅정과 어머니 길은자의 차남으로 태어나 그곳에서 자랐다.\",\n",
    "    \"형은 손흥윤이다.\",\n",
    "    \"춘천 부안초등학교를 졸업했고, 춘천 후평중학교에 입학한 후 2학년때 원주 육민관중학교 축구부에 들어가기 위해 전학하여 졸업하였으며, 2008년 당시 FC 서울의 U-18팀이었던 동북고등학교 축구부에서 선수 활동 중 대한축구협회 우수선수 해외유학 프로젝트에 선발되어 2008년 8월 독일 분데스리가의 함부르크 유소년팀에 입단하였다.\",\n",
    "    \"함부르크 유스팀 주전 공격수로 2008년 6월 네덜란드에서 열린 4개국 경기에서 4게임에 출전, 3골을 터뜨렸다.\",\n",
    "    \"1년간의 유학 후 2009년 8월 한국으로 돌아온 후 10월에 개막한 FIFA U-17 월드컵에 출전하여 3골을 터트리며 한국을 8강으로 이끌었다.\",\n",
    "    \"그해 11월 함부르크의 정식 유소년팀 선수 계약을 체결하였으며 독일 U-19 리그 4경기 2골을 넣고 2군 리그에 출전을 시작했다.\",\n",
    "    \"독일 U-19 리그에서 손흥민은 11경기 6골, 2부 리그에서는 6경기 1골을 넣으며 재능을 인정받아 2010년 6월 17세의 나이로 함부르크의 1군 팀 훈련에 참가, 프리시즌 활약으로 함부르크와 정식 계약을 한 후 10월 18세에 함부르크 1군 소속으로 독일 분데스리가에 데뷔하였다.\",\n",
    "]\n",
    "document_embeddings = model.encode(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40059cf-6c9a-423c-a1e6-da0105512fd8",
   "metadata": {},
   "source": [
    "이제 입력 문장을 임베딩 할 차례입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "366338dd-1894-4b0f-9392-6afaeb11d1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da5538062084313b059d534a369153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"손흥민은 어린 나이에 유럽에 진출하였다.\"\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466fccb3-ea9b-4eec-b342-939c3f38a154",
   "metadata": {},
   "source": [
    "아래는 입력된 문장의 임베딩과 미리 임베딩 된 후보군 문장 임베딩 간 유사도를 계산해 유사도가 높은 순서대로 `top_k` 개 문장을 뽑아주는 예제 코드입니다.\n",
    "\n",
    "`top_k`는 전체 문장 후보군의 개수를 넘지 않아야 하므로, `min()` 함수를 통해 예외 처리를 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f89cc4a9-c001-410c-8974-b351ac7cd30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3986, 0.2794, 0.3515, 0.3547, 0.2523, 0.4543, 0.5872])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9f0a5354-91ba-4471-8241-43d8269298cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 손흥민은 어린 나이에 유럽에 진출하였다.\n",
      "\n",
      "<입력 문장과 유사한 5 개의 문장>\n",
      "\n",
      "1: 독일 U-19 리그에서 손흥민은 11경기 6골, 2부 리그에서는 6경기 1골을 넣으며 재능을 인정받아 2010년 6월 17세의 나이로 함부르크의 1군 팀 훈련에 참가, 프리시즌 활약으로 함부르크와 정식 계약을 한 후 10월 18세에 함부르크 1군 소속으로 독일 분데스리가에 데뷔하였다. (유사도: 0.5872)\n",
      "\n",
      "2: 그해 11월 함부르크의 정식 유소년팀 선수 계약을 체결하였으며 독일 U-19 리그 4경기 2골을 넣고 2군 리그에 출전을 시작했다. (유사도: 0.4543)\n",
      "\n",
      "3: 1992년 7월 8일 손흥민은 강원도 춘천시 후평동에서 아버지 손웅정과 어머니 길은자의 차남으로 태어나 그곳에서 자랐다. (유사도: 0.3986)\n",
      "\n",
      "4: 함부르크 유스팀 주전 공격수로 2008년 6월 네덜란드에서 열린 4개국 경기에서 4게임에 출전, 3골을 터뜨렸다. (유사도: 0.3547)\n",
      "\n",
      "5: 춘천 부안초등학교를 졸업했고, 춘천 후평중학교에 입학한 후 2학년때 원주 육민관중학교 축구부에 들어가기 위해 전학하여 졸업하였으며, 2008년 당시 FC 서울의 U-18팀이었던 동북고등학교 축구부에서 선수 활동 중 대한축구협회 우수선수 해외유학 프로젝트에 선발되어 2008년 8월 독일 분데스리가의 함부르크 유소년팀에 입단하였다. (유사도: 0.3515)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_k = min(5, len(docs))\n",
    "\n",
    "# 입력 문장 - 문장 후보군 간 코사인 유사도 계산 후,\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "# 코사인 유사도 순으로 `top_k` 개 문장 추출\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"\\n<입력 문장과 유사한 {top_k} 개의 문장>\\n\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    print(f\"{i+1}: {docs[idx]} {'(유사도: {:.4f})'.format(score)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc7686-4318-498c-9261-e4b92a5d0c4b",
   "metadata": {},
   "source": [
    "반환된 문장 중 `유럽`, `어린 나이` 등의 키워드가 없음애도 높은 유사도로 두 문장이 반환된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9bc75-1413-410b-bd44-9f68b0f78032",
   "metadata": {},
   "source": [
    "### 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fdc0c-7cb6-4538-9cd8-eb983dc086bf",
   "metadata": {},
   "source": [
    "`sentence-transformers`를 통해 얻어진 임베딩을 활용해 클러스터링을 수행할 수도 있습니다.\n",
    "\n",
    "다양한 클러스터링 기법의 적용이 가능하겠지만, 본 노트북에서는 **k-Means** 클러스터링을 수행한 결과를 살펴보도록 합니다.\n",
    "\n",
    "예제 수행을 위해 `scikit-learn`의 설치가 추가로 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "be615a4d-f482-4d24-b77c-431eeefa5b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://kakaobrain-pypi.dev.9rum.cc/\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a55f9168-ba61-4f18-b458-b10b1e3c90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2096a-d683-4713-889d-46a368e9888c",
   "metadata": {},
   "source": [
    "마찬가지로 앞서 구축한 문장 후보군들에 대해 임베딩을 수행합니다.\n",
    "\n",
    "이후, `num_clusters` 변수를 통해 클러스터의 개수를 설정한 후 임베딩을 활용한 **k-Means** 클러스터링을 수행하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9771e341-3902-427e-a7c2-72d71804d63f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12239c6d9d944e2db409187fa177b518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "document_embeddings = model.encode(docs)\n",
    "\n",
    "# Perform kmean clustering\n",
    "num_clusters = 3\n",
    "\n",
    "k_means = KMeans(n_clusters=num_clusters)\n",
    "k_means.fit(document_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82676eb-3046-40b7-af1a-fac8521b4002",
   "metadata": {},
   "source": [
    "이제 클러스터링을 통해 각 문장이 어떤 클러스터에 포함되었는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9a84c048-594a-4c09-ae1b-732c96a06c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignment = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "19df02ff-2b3a-4934-92e6-84d14b653974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539ad61-5d5c-4d6a-9f38-0002aeb3c7f1",
   "metadata": {},
   "source": [
    "클러스터링 결과를 토대로 각 문장을 클러스터로 분리한 후, 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e25e6d9-2b2c-4564-a414-b470f8473b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 클러스터 1 >\n",
      "1992년 7월 8일 손흥민은 강원도 춘천시 후평동에서 아버지 손웅정과 어머니 길은자의 차남으로 태어나 그곳에서 자랐다.\n",
      "춘천 부안초등학교를 졸업했고, 춘천 후평중학교에 입학한 후 2학년때 원주 육민관중학교 축구부에 들어가기 위해 전학하여 졸업하였으며, 2008년 당시 FC 서울의 U-18팀이었던 동북고등학교 축구부에서 선수 활동 중 대한축구협회 우수선수 해외유학 프로젝트에 선발되어 2008년 8월 독일 분데스리가의 함부르크 유소년팀에 입단하였다.\n",
      "1년간의 유학 후 2009년 8월 한국으로 돌아온 후 10월에 개막한 FIFA U-17 월드컵에 출전하여 3골을 터트리며 한국을 8강으로 이끌었다.\n",
      "\n",
      "< 클러스터 2 >\n",
      "함부르크 유스팀 주전 공격수로 2008년 6월 네덜란드에서 열린 4개국 경기에서 4게임에 출전, 3골을 터뜨렸다.\n",
      "그해 11월 함부르크의 정식 유소년팀 선수 계약을 체결하였으며 독일 U-19 리그 4경기 2골을 넣고 2군 리그에 출전을 시작했다.\n",
      "독일 U-19 리그에서 손흥민은 11경기 6골, 2부 리그에서는 6경기 1골을 넣으며 재능을 인정받아 2010년 6월 17세의 나이로 함부르크의 1군 팀 훈련에 참가, 프리시즌 활약으로 함부르크와 정식 계약을 한 후 10월 18세에 함부르크 1군 소속으로 독일 분데스리가에 데뷔하였다.\n",
      "\n",
      "< 클러스터 3 >\n",
      "형은 손흥윤이다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 클러스터 개수 만큼 문장을 담을 리스트 초기화\n",
    "clustered_sentences = [[] for _ in range(num_clusters)]\n",
    "\n",
    "# 클러스터링 결과를 돌며 각 클러스터에 맞게 문장 삽입\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(docs[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    result = \"\\n\".join(cluster)\n",
    "    print(f\"< 클러스터 {i+1} >\\n{result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e837f7d-19b3-47d7-b08a-2e35d41bc937",
   "metadata": {},
   "source": [
    "국내 관련 문장과 해외 관련 문장, 가족 관계와 같은 느낌으로 클러스터가 형성된 것을 확인할 수 있습니다.\n",
    "\n",
    "지금까지 `sentence-transformers`를 학습하는 과정을 KLUE STS 데이터셋을 통해 알아보았습니다.\n",
    "\n",
    "`sentence-transformers`는 다양한 문장 임베딩 기법과 이를 활용한 응용 사례에 대해서 크게 고민하는 **UKPLab**에서 관리되는 라이브러리이니 만큼 앞으로 더 발전하고 관리될 가능성이 높은 도구입니다.\n",
    "\n",
    "본 노트북을 통해 습득한 지식이 여러분의 업무와 학습에 도움이 되었으면 좋겠습니다.\n",
    "\n",
    "```\n",
    "허 훈 (huffonism@gmail.com)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
