{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "natural-language-inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kbUSCb_Egcu"
      },
      "source": [
        "# HuggingFace Transformers를 활용한 문장 분류 모델 학습"
      ],
      "id": "_kbUSCb_Egcu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of2izij8Eqe0"
      },
      "source": [
        "본 노트북에서는 `klue/roberta-base` 모델을 **KLUE** 내 **NLI** 데이터셋을 활용하여 모델을 훈련하는 예제를 다루게 됩니다.\n",
        "\n",
        "학습을 통해 얻어질 `klue-roberta-base-nli` 모델은 입력된 두 문장의 추론 관계를 예측하는데 사용할 수 있게 됩니다.\n",
        "\n",
        "학습 과정 이후에는 간단한 예제 코드를 통해 모델이 어떻게 활용되는지도 함께 알아보도록 할 것입니다.\n",
        "\n",
        "모든 소스 코드는 [`huggingface-notebooks`](https://github.com/huggingface/notebooks)를 참고하였습니다.\n",
        "\n",
        "먼저, 노트북을 실행하는데 필요한 라이브러리를 설치합니다. 모델 훈련을 위해서는 `transformers`가, 학습 데이터셋 로드를 위해서는 `datasets` 라이브러리의 설치가 필요합니다. 그 외 모델 성능 검증을 위해 `scipy`, `scikit-learn`을 추가로 설치해주도록 합니다."
      ],
      "id": "of2izij8Eqe0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e59dc52"
      },
      "source": [
        "# !pip install -U transformers datasets scipy scikit-learn"
      ],
      "id": "8e59dc52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSLfX-jaIqV"
      },
      "source": [
        "## 문장 분류 모델 학습"
      ],
      "id": "8wSLfX-jaIqV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92e868b7-3cf7-4977-a6e7-ebbb99ba298e"
      },
      "source": [
        "노트북을 실행하는데 필요한 라이브러리들을 모두 임포트합니다."
      ],
      "id": "92e868b7-3cf7-4977-a6e7-ebbb99ba298e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "243b461f"
      },
      "source": [
        "import random\n",
        "import logging\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ],
      "id": "243b461f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59b1e5ae-471f-461f-850f-4241a6037471"
      },
      "source": [
        "학습에 필요한 정보를 변수로 기록합니다.\n",
        "\n",
        "본 노트북에서는 `klue-roberta-base` 모델을 활용하지만, https://huggingface.co/klue 페이지에서 더 다양한 사전학습 언어 모델을 확인하실 수 있습니다.\n",
        "\n",
        "학습 태스크로는 `nli`를, 배치 사이즈로는 32를 지정하겠습니다."
      ],
      "id": "59b1e5ae-471f-461f-850f-4241a6037471"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ecaacbe"
      },
      "source": [
        "model_checkpoint = \"klue/roberta-base\"\n",
        "batch_size = 32\n",
        "task = \"nli\""
      ],
      "id": "6ecaacbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "816b5893-d03e-4c6e-8536-e246b1def987"
      },
      "source": [
        "이제 HuggingFace `datasets` 라이브러리에 등록된 KLUE 데이터셋 중, NLI 데이터를 내려받습니다."
      ],
      "id": "816b5893-d03e-4c6e-8536-e246b1def987"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8feeba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3527b5-3138-4cd9-82ba-f0d1531e7547"
      },
      "source": [
        "datasets = load_dataset(\"klue\", task)"
      ],
      "id": "f8feeba0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset klue (/root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f90b06e4-3795-435a-aec8-701da9bd5f04"
      },
      "source": [
        "다운로드 혹은 로드 후 얻어진 `datasets` 객체를 살펴보면, 훈련 데이터와 검증 데이터가 포함되어 있는 것을 확인할 수 있습니다."
      ],
      "id": "f90b06e4-3795-435a-aec8-701da9bd5f04"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzlmWQ2DrZ7P",
        "outputId": "aa31c09e-878d-4fe6-a02e-a640a33fa0a2"
      },
      "source": [
        "datasets"
      ],
      "id": "QzlmWQ2DrZ7P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['guid', 'hypothesis', 'label', 'premise', 'source'],\n",
              "        num_rows: 24998\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['guid', 'hypothesis', 'label', 'premise', 'source'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f39_pKKnarD3"
      },
      "source": [
        "각 예시 데이터는 아래와 같이 두 개의 문장과 두 문장의 추론 관계를 라벨로 지니고 있습니다."
      ],
      "id": "f39_pKKnarD3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e46bf44d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58097cf0-e194-4d39-c4dd-fdff48fd2d66"
      },
      "source": [
        "datasets[\"train\"][0]"
      ],
      "id": "e46bf44d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'guid': 'klue-nli-v1_train_00000',\n",
              " 'hypothesis': '힛걸 진심 최고로 멋지다.',\n",
              " 'label': 0,\n",
              " 'premise': '힛걸 진심 최고다 그 어떤 히어로보다 멋지다',\n",
              " 'source': 'NSMC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc1BXYLYaupD"
      },
      "source": [
        "데이터셋을 전반적으로 살펴보기 위한 시각화 함수를 다음과 같이 정의합니다."
      ],
      "id": "pc1BXYLYaupD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8110a3ee"
      },
      "source": [
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "\n",
        "    picks = []\n",
        "    \n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "\n",
        "        # 이미 등록된 예제가 뽑힌 경우, 다시 추출\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "\n",
        "        picks.append(pick)\n",
        "\n",
        "    # 임의로 추출된 인덱스들로 구성된 데이터 프레임 선언\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "\n",
        "    for column, typ in dataset.features.items():\n",
        "        # 라벨 클래스를 스트링으로 변환\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "\n",
        "    display(HTML(df.to_html()))"
      ],
      "id": "8110a3ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1Ia2wGh1xaF"
      },
      "source": [
        "앞서 정의한 함수를 활용해 훈련 데이터를 살펴보도록 합시다.\n",
        "\n",
        "이처럼 데이터를 살펴보는 것의 장점으로는 각 라벨에 어떠한 문장들이 해당하는지에 대한 감을 익힐 수 있다는데에 있습니다.\n",
        "\n",
        "**KLUE NLI**는 `entailment`, `neutral` 그리고 `contradiction` 세 개의 라벨을 지니는 데이터셋임을 확인할 수 있습니다."
      ],
      "id": "u1Ia2wGh1xaF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8c7888d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "defb8d73-d864-49ce-c04d-aa39d01c694a"
      },
      "source": [
        "show_random_elements(datasets[\"train\"])"
      ],
      "id": "8c7888d1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>premise</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>klue-nli-v1_train_00311</td>\n",
              "      <td>메리는 아이가 없다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>1년 후, 메리는 마침내 맥스를 방문하기 위해 그녀의 아기와 함께 뉴욕으로 간다.</td>\n",
              "      <td>wikipedia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>klue-nli-v1_train_18179</td>\n",
              "      <td>잠수함 사령부는 경기도에 위치해있다.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>잠수함 사령부에서는 잠수함 건조국인 독일에서 찾지 못한 결함을 찾을 정도로 기량도 발군이다.</td>\n",
              "      <td>wikinews</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>klue-nli-v1_train_15000</td>\n",
              "      <td>위치때문에 만족스러웠습니다.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>위치가 불편함을 느낄정도는 아니었습니다.</td>\n",
              "      <td>airbnb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>klue-nli-v1_train_05633</td>\n",
              "      <td>달스턴에 있는 모든 숙소는 조용하고 쾌적합니다.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>달스턴에 있는 조용하고 쾌적한 숙소입니다.</td>\n",
              "      <td>airbnb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>klue-nli-v1_train_13825</td>\n",
              "      <td>영화 아이언맨의 팬으로서 진짜 기분 좋습니다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>영화 아이언맨의 팬으로서 진짜 기분 더럽습니다.</td>\n",
              "      <td>NSMC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>klue-nli-v1_train_04142</td>\n",
              "      <td>기본적인 잠자리와 숙박은 불만스럽지 않았습니다.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>기본적인 잠자리나 숙박에 관해서는 편안합니다.</td>\n",
              "      <td>airbnb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>klue-nli-v1_train_05472</td>\n",
              "      <td>다윈은 자연에 대한 관심이 없었다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>다윈은 그의 과학적 사상, 자연에 대한 관심 등을 장편의 시로 표현하고는 하였다.</td>\n",
              "      <td>wikipedia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>klue-nli-v1_train_23884</td>\n",
              "      <td>요기요 앱은 다운로드 기능을 제공하지 않는다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>할인 쿠폰은 요기요 앱에서 다운받을 수 있다.</td>\n",
              "      <td>wikitree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>klue-nli-v1_train_02134</td>\n",
              "      <td>포함된 방안에는 정부 지원사업 신청서류 축소 뿐이었다.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>공공기관 보유토지 사용료율을 낮추고 조달업체 선금지급 시 장벽완화, 정부 지원사업 신청서류 축소 등 방안이 포함됐다.</td>\n",
              "      <td>policy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>klue-nli-v1_train_10020</td>\n",
              "      <td>사진과 위치를 호스트가 소개해주었습니다.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>사진과 위치 모두 소개된 대로 였습니다.</td>\n",
              "      <td>airbnb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zakMS4Y61sLm"
      },
      "source": [
        "훈련 과정 중 모델의 성능을 파악하기 위한 메트릭을 설정합니다.\n",
        "\n",
        "`datasets` 라이브러리에는 이미 구현된 메트릭을 사용할 수 있는 `load_metric` 함수가 있습니다.\n",
        "\n",
        "그 중 **GLUE** 데이터셋에 이미 다양한 메트릭이 구현되어 있으므로, **GLUE** 그 중에서도 **KLUE NLI**와 동일한 `accuracy` 메트릭을 사용하는 `qnli` 태스크의 메트릭을 사용합니다."
      ],
      "id": "zakMS4Y61sLm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c214cfb-efa2-4e31-9268-9d1038626095"
      },
      "source": [
        "metric = load_metric(\"glue\", \"qnli\")"
      ],
      "id": "5c214cfb-efa2-4e31-9268-9d1038626095",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I07wSysL2fRs"
      },
      "source": [
        "`accuracy` 메트릭이 정상적으로 작동하는지 확인하기 위해, 랜덤한 예측 값과 라벨 값을 생성합니다."
      ],
      "id": "I07wSysL2fRs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e988c49f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db123b79-f250-436c-a3a9-17a0317bd7a1"
      },
      "source": [
        "fake_preds = np.random.randint(0, 2, size=(64,))\n",
        "fake_labels = np.random.randint(0, 2, size=(64,))\n",
        "fake_preds, fake_labels"
      ],
      "id": "e988c49f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
              " array([0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryxIEDZR2oR-"
      },
      "source": [
        "앞서 생성한 랜덤 예측, 랜덤 라벨 값을 `compute()` 함수에 입력해 잘 동작하는지 확인해봅시다."
      ],
      "id": "ryxIEDZR2oR-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2dcf392-5c0a-4bbb-b9f6-cc42be6a382a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356e3922-1401-42c5-a583-61c776a8025d"
      },
      "source": [
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "id": "e2dcf392-5c0a-4bbb-b9f6-cc42be6a382a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.515625}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPvvy_wC24i_"
      },
      "source": [
        "이제 학습에 활용할 토크나이저를 로드해오도록 합니다."
      ],
      "id": "rPvvy_wC24i_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b64e70af"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "id": "b64e70af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIVjwvm428Q_"
      },
      "source": [
        "로드된 토크나이저가 두 개 문장을 토큰화하는 방식을 파악하기 위해 두 문장을 입력 값으로 넣어줘보도록 합시다."
      ],
      "id": "YIVjwvm428Q_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0520aba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e602f34d-f77d-407c-bf57-24bf3882c2ab"
      },
      "source": [
        "tokenizer(\"힛걸 진심 최고로 멋지다.\", \"힛걸 진심 최고다 그 어떤 히어로보다 멋지다\")"
      ],
      "id": "0520aba3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 1, 7254, 3841, 2200, 11980, 2062, 18, 3, 1, 7254, 3841, 2062, 636, 3711, 12717, 2178, 2062, 11980, 2062, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDAaxujL7l1X"
      },
      "source": [
        "`input_ids`를 보시면 `cls_token`에 해당하는 2번 토큰이 가장 좌측에 붙게 되며, `sep_token`의 3번 토큰이 각각 중간과 가장 우측에 더해진 것을 확인할 수 있습니다.\n",
        "\n",
        "이제 앞서 로드한 데이터셋에서 각 문장에 해당하는 *value* 를 뽑아주기 위한 *key* 를 정의합니다.\n",
        "\n",
        "앞서 **KLUE NLI** 데이터셋의 두 문장은 각각 `premise`와 `hypothesis`라는 이름으로 정의된 것을 확인하였으니, 두 문장의 *key* 는 마찬가지로 각각 `premise`, `hypothesis`가 되게 됩니다."
      ],
      "id": "FDAaxujL7l1X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95127c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e98767e-5758-4f73-f6e0-074ffad6e4a1"
      },
      "source": [
        "sentence1_key, sentence2_key = (\"premise\", \"hypothesis\")\n",
        "print(f\"Sentence 1: {datasets['train'][0][sentence1_key]}\")\n",
        "print(f\"Sentence 2: {datasets['train'][0][sentence2_key]}\")"
      ],
      "id": "95127c8c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 1: 힛걸 진심 최고다 그 어떤 히어로보다 멋지다\n",
            "Sentence 2: 힛걸 진심 최고로 멋지다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMDIRs1M4-5a"
      },
      "source": [
        "이제 *key* 도 확인이 되었으니, 데이터셋에서 각 예제들을 뽑아와 토큰화 할 수 있는 함수를 아래와 같이 정의해줍니다.\n",
        "\n",
        "해당 함수는 모델을 훈련하기 앞서 데이터셋을 미리 토큰화 시켜놓는 작업을 위한 콜백 함수로 사용되게 됩니다.\n",
        "\n",
        "인자로 넣어주는 `truncation`는 모델이 입력 받을 수 있는 최대 길이 이상의 토큰 시퀀스가 들어오게 될 경우, 최대 길이 기준으로 시퀀스를 자르라는 의미를 지닙니다.\n",
        "\n",
        "( \\* `return_token_type_ids`는 토크나이저가 `token_type_ids`를 반환하도록 할 것인지를 결정하는 인자입니다. `transformers==4.7.0` 기준으로 `token_type_ids`가 기본적으로 반환되므로 `token_type_ids` 자체를 사용하지 않는 `RoBERTa` 모델을 활용하기 위해 해당 인자를 `False`로 설정해주도록 합니다.)"
      ],
      "id": "fMDIRs1M4-5a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f8f8cc0"
      },
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[sentence1_key],\n",
        "        examples[sentence2_key],\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False,\n",
        "    )"
      ],
      "id": "2f8f8cc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-qK5fgl4_6t"
      },
      "source": [
        "앞서 정의한 `process_function`은 여러 개의 예제 데이터를 받을 수도 있습니다."
      ],
      "id": "F-qK5fgl4_6t"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8KrAGLpyxNO",
        "outputId": "c547f152-664b-4d04-fd23-9c84d409c4db"
      },
      "source": [
        "preprocess_function(datasets['train'][:5])"
      ],
      "id": "x8KrAGLpyxNO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[2, 1, 7254, 3841, 2062, 636, 3711, 12717, 2178, 2062, 11980, 2062, 3, 1, 7254, 3841, 2200, 11980, 2062, 18, 3], [2, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 3, 3911, 2377, 2366, 1525, 2062, 18, 3], [2, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 3, 1282, 2955, 3308, 2052, 3944, 11580, 2359, 2062, 18, 3], [2, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 3, 3911, 2377, 2366, 5105, 2318, 831, 717, 2886, 2069, 575, 555, 2062, 18, 3], [2, 10522, 2548, 2500, 6328, 2170, 6189, 5916, 4015, 2116, 1039, 2219, 3606, 18, 3, 10522, 2548, 2500, 6328, 27135, 5916, 4015, 1642, 2015, 2259, 4258, 2219, 3606, 18, 3]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_usMC7U5AyW"
      },
      "source": [
        "이제 정의된 전처리 함수를 활용해 데이터셋을 미리 토큰화시키는 작업을 수행합니다.\n",
        "\n",
        "`datasets` 라이브러리를 통해 얻어진 `DatasetDict` 객체는 `map()` 함수를 지원하므로, 정의된 전처리 함수를 데이터셋 토큰화를 위한 콜백 함수로 `map()` 함수 인자로 넘겨주면 됩니다.\n",
        "\n",
        "보다 자세한 내용은 [문서](https://huggingface.co/docs/datasets/processing.html#processing-data-with-map)를 참조해주시면 됩니다."
      ],
      "id": "a_usMC7U5AyW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7c72286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f50865-5955-4e42-dfd5-891230fd8416"
      },
      "source": [
        "encoded_datasets = datasets.map(preprocess_function, batched=True)"
      ],
      "id": "f7c72286",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90/cache-af02c8d85388eb5e.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90/cache-22fabae8d7495d91.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6p7zIL75Bif"
      },
      "source": [
        "학습을 위한 모델을 로드할 차례입니다.\n",
        "\n",
        "앞서 살펴본 바와 같이 **KLUE NLI**에는 총 3개의 클래스가 존재하므로, 3개의 클래스를 예측할 수 있는 *SequenceClassification* 구조로 모델을 로드하도록 합니다."
      ],
      "id": "n6p7zIL75Bif"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ae93dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbcf2db-cfc3-4141-8149-5152c6160a76"
      },
      "source": [
        "num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ],
      "id": "7ae93dd8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSc4c6K5oR_R"
      },
      "source": [
        "모델을 로드할 때 발생하는 경고 문구는 두 가지 의미를 지닙니다.\n",
        "\n",
        "1. *Masked Language Modeling* 을 위해 존재했던 `lm_head`가 현재는 사용되지 않고 있음을 의미합니다.\n",
        "2. 문장 분류를 위한 `classifier` 레이어를 백본 모델 뒤에 이어 붙였으나 아직 훈련이 되지 않았으므로, 학습을 수행해야 함을 의미합니다."
      ],
      "id": "ZSc4c6K5oR_R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6bvKcsv5CPo"
      },
      "source": [
        "마지막으로 앞서 정의한 메트릭을 모델 예측 결과에 적용하기 위한 함수를 정의합니다.\n",
        "\n",
        "입력으로 들어오는 `eval_pred`는 [*EvalPrediction*](https://huggingface.co/transformers/internal/trainer_utils.html#transformers.EvalPrediction) 객체이며, 모델의 클래스 별 예측 값과 정답 값을 지닙니다.\n",
        "\n",
        "클래스 별 예측 중 가장 높은 라벨을 `argmax()`를 통해 뽑아낸 후, 정답 라벨과 비교를 하게 됩니다."
      ],
      "id": "x6bvKcsv5CPo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbfb67d3"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "id": "cbfb67d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU_dmMAVE_FA"
      },
      "source": [
        "이제 앞서 정의한 정보들을 바탕으로 `transformers`에서 제공하는 *Trainer* 객체를 활용하기 위한 인자 관리 클래스를 초기화합니다.\n",
        "\n",
        "`metric_name`은 앞서 얻어진 메트릭 함수를 활용했을 때, 아래와 같이 `dict` 형식으로 결과 값이 반환되는데 여기서 우리가 사용할 *key* 를 정의해준다고 생각하시면 됩니다.\n",
        "\n",
        "```python\n",
        ">>> metric.compute(predictions=fake_preds, references=fake_labels)\n",
        "{'accuracy': 0.515625}\n",
        "```\n",
        "\n",
        "각 인자에 대한 자세한 설명은 [문서](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments)에서 참조해주시면 됩니다."
      ],
      "id": "aU_dmMAVE_FA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "864b6408"
      },
      "source": [
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"test-{task}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        ")"
      ],
      "id": "864b6408",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcvI6ZHe3Ty6"
      },
      "source": [
        "이제 로드한 모델, 인자 관리 클래스, 데이터셋 등을 *Trainer* 클래스를 초기화에 넘겨주도록 합니다.\n",
        "\n",
        "(TIP: Q: 이미 `encoded_datasets`을 만드는 과정에 토큰화가 이루어졌는데 토크나이저를 굳이 넘겨주는 이유가 무엇인가요?,<br>A: 토큰화는 이루어졌지만 학습 과정 시, 데이터를 배치 단위로 넘겨주는 과정에서 배치에 포함된 가장 긴 시퀀스 기준으로 `truncation`을 수행하고 최대 길이 시퀀스 보다 짧은 시퀀스들은 그 길이만큼 `padding`을 수행해주기 위함입니다.)"
      ],
      "id": "PcvI6ZHe3Ty6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c91650f2"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_datasets[\"train\"],\n",
        "    eval_dataset=encoded_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "id": "c91650f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KImxQi1ZFAO4"
      },
      "source": [
        "이제 정의된 *Trainer* 객체를 다음과 같이 훈련시킬 수 있습니다.\n",
        "\n",
        "에폭이 지남에 따라 *Loss* 는 떨어지고, 앞서 선정한 메트릭인 *Accuracy* 는 증가하는 것을 확인할 수 있습니다."
      ],
      "id": "KImxQi1ZFAO4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73261f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "ecee038f-01b4-4b09-df5f-dcc55cf96016"
      },
      "source": [
        "trainer.train()"
      ],
      "id": "73261f8e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3910/3910 29:21, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.576600</td>\n",
              "      <td>0.459994</td>\n",
              "      <td>0.839667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.271800</td>\n",
              "      <td>0.421251</td>\n",
              "      <td>0.857000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.165600</td>\n",
              "      <td>0.445249</td>\n",
              "      <td>0.857667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.604087</td>\n",
              "      <td>0.863667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.064100</td>\n",
              "      <td>0.688019</td>\n",
              "      <td>0.866333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3910, training_loss=0.21999031222994675, metrics={'train_runtime': 1761.9721, 'train_samples_per_second': 70.938, 'train_steps_per_second': 2.219, 'total_flos': 5701283955554040.0, 'train_loss': 0.21999031222994675, 'epoch': 5.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avS6mBu8779g"
      },
      "source": [
        "*Trainer* 는 학습을 마치게 되면, `load_best_model_at_end=True` 인자에 따라 메트릭 기준 가장 좋은 성능을 보였던 체크포인트를 로드하게 됩니다.\n",
        "\n",
        "본 노트북에서는 마지막 에폭 때 가장 좋은 성능을 얻었기에 `evaluate`를 수행해도 같은 결과가 나오겠습니다."
      ],
      "id": "avS6mBu8779g"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58239e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c6bb569e-9a90-4134-f555-c0af0cb72d29"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "id": "58239e17",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [94/94 00:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_accuracy': 0.8663333333333333,\n",
              " 'eval_loss': 0.6880185604095459,\n",
              " 'eval_runtime': 12.7427,\n",
              " 'eval_samples_per_second': 235.429,\n",
              " 'eval_steps_per_second': 7.377}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stk6rOUyFJuM"
      },
      "source": [
        "지금까지 `transformers`를 라이브러리 내 문장 분류 모델을 학습하는 과정을 KLUE NLI 데이터셋을 통해 알아보았습니다.\n",
        "\n",
        "본 노트북을 통해 습득한 지식이 여러분의 업무와 학습에 도움이 되었으면 좋겠습니다.\n",
        "\n",
        "```\n",
        "허 훈 (huffonism@gmail.com)\n",
        "```"
      ],
      "id": "stk6rOUyFJuM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkNpAqSJ78oM"
      },
      "source": [
        "APPENDIX: 앞서 학습된 모델을 HuggingFace 모델 허브에 업로드하였으니, 아래 예제와 같이 `pipeline` 함수를 통해 사용이 가능합니다.\n",
        "\n",
        "먼저 `text-classification` 태스크로 파이프라인 객체를 초기화합니다.\n",
        "\n",
        "( \\* `return_all_scores`는 모델이 입력 문장에 대해 측정한 각 라벨에 대한 확률 값을 모두 보여줄 것인지를 결정하는 인자입니다.)"
      ],
      "id": "SkNpAqSJ78oM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htUZ0ws19Ksk"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"Huffon/klue-roberta-base-nli\",\n",
        "    return_all_scores=True,\n",
        ")"
      ],
      "id": "htUZ0ws19Ksk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uW7UQgBFBPw"
      },
      "source": [
        "NLI는 두 문장의 페어를 입력 값으로 주어야 하기 때문에 구분자 스페셜 토큰을 두 문장 사이에 넣어주기 위해 토크나이저 객체를 로드합니다.\n",
        "\n",
        "`[SEP]` 문자열을 하드코딩하여 넣어줄 수도 있겠지만, 스페셜 토큰은 토크나이저 마다 다르게 정의되므로 다른 모델을 활용할 때 보다 코드를 재사용할 수 있도록 토크나이저의 `sep_token` 프로퍼티에 접근하는 방식으로 코드를 작성합니다."
      ],
      "id": "2uW7UQgBFBPw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoXTmep0Dcwg"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Huffon/klue-roberta-base-nli\")"
      ],
      "id": "UoXTmep0Dcwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MuOQhiVPDiMq",
        "outputId": "6c7f4d51-ceb9-4650-e5d6-19d4f6b604ac"
      },
      "source": [
        "tokenizer.sep_token"
      ],
      "id": "MuOQhiVPDiMq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCP9OgWHFDLG"
      },
      "source": [
        "`sep_token`으로 두 문장을 이어 하나의 입력 값으로 파이프라인에 넘겨줍니다.\n",
        "\n",
        "입력된 문장에 대해 모델이 각 라벨에 대해 어떤 확률을 가지고 예측했는지를 확인할 수 있습니다."
      ],
      "id": "iCP9OgWHFDLG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVCGIVQDChcQ",
        "outputId": "f2703b6f-90c0-4107-cd6b-9f2e265713cc"
      },
      "source": [
        "classifier(f\"흡연하려면 발코니 있는 방을 선택하면 됩니다. {tokenizer.sep_token} 흡연자분들은 발코니가 있는 방이면 발코니에서 흡연이 가능합니다.\")"
      ],
      "id": "tVCGIVQDChcQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'ENTAILMENT', 'score': 0.9865273833274841},\n",
              "  {'label': 'NEUTRAL', 'score': 0.013215206563472748},\n",
              "  {'label': 'CONTRADICTION', 'score': 0.0002573762903921306}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud2kuxlNCmGI",
        "outputId": "7d53c878-9fb1-4e05-da40-ab06df811a1f"
      },
      "source": [
        "classifier(f\"호스트분은 영어밖에 못하십니다. {tokenizer.sep_token} 호스트분도 엄청 친절하시고 영어도 잘하십니다.\")"
      ],
      "id": "Ud2kuxlNCmGI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'ENTAILMENT', 'score': 0.0002685467479750514},\n",
              "  {'label': 'NEUTRAL', 'score': 0.0006742384284734726},\n",
              "  {'label': 'CONTRADICTION', 'score': 0.9990572333335876}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvx8PPTsrPyC"
      },
      "source": [
        "검증 데이터에 존재하는 임의의 문장 페어를 입력해보니, 우리가 원하던 결과를 얻을 수 있었습니다.\n",
        "\n",
        "*(cf. NLI 데이터에 대해 학습된 모델을 활용해 Zero-shot Classification을 수행하는 예제가 궁금하신 분들은 해당 [노트북](https://colab.research.google.com/github/Huffon/klue-transformers-tutorial/blob/master/zero_shot_classification.ipynb)을 참조해주세요.)*"
      ],
      "id": "Uvx8PPTsrPyC"
    }
  ]
}